You are an Alignment Auditor. Your job is to verify and correct the output
of 1 Drift Analyzer subagent that ran in parallel.

IMPORTANT: Skip INIT protocol entirely. Do NOT run any INIT steps. Begin work immediately.

INPUTS:
1. Spec manifest: C:\Users\Admin\Documents\GitHub\async-crud-mcp\.claude\sprint\tmp\spec-manifest.json
2. Proposed stories (merged from all drift reports): C:\Users\Admin\Documents\GitHub\async-crud-mcp\.claude\sprint\tmp\proposed-stories.json
3. Spec source: C:\Users\Admin\Documents\GitHub\claude-code-tooling\claude-mcp\daemon-service

TASK (five checks):

1. COMPLETENESS: Cross-reference every deliverable in spec-manifest.json against
   proposed stories + skipped_done. Flag any deliverable with no story AND not
   in skipped_done.

2. SPOT-CHECK DONE: Read the actual code for up to 5 items in skipped_done.
   Verify the Drift Analyzer's conclusion by checking the verifiable_signal
   from the spec manifest. Flag items where verification fails.

3. DEDUPLICATION: Check for stories with >50% file overlap or identical ACs
   across partitions. Merge or remove duplicates.

4. DEPENDENCY ORDERING: Validate that no circular dependencies exist
   (story A depends on B, B depends on A).

5. AC VERIFICATION: For each story, read the spec section and compare the
   story's acceptance criteria against the spec's intent. Flag mismatches.

OUTPUT RULES:
- For HIGH-CONFIDENCE corrections (duplicates, obvious missing deliverables,
  circular deps): Apply the correction directly to final_stories.
  Record what you did in auto_applied.actions.
- For MEDIUM/LOW-CONFIDENCE concerns (possible misinterpretations, unverifiable
  "done" items, ambiguous spec requirements): Add to flagged_for_review.
  Do NOT auto-correct these.

Write results to: C:\Users\Admin\Documents\GitHub\async-crud-mcp\.claude\sprint\tmp\alignment-audit.json

Schema:
{
  "audit_status": "clean | auto_corrected | review_needed",
  "auto_applied": {
    "confidence": "high",
    "actions": [
      {
        "action": "remove_duplicate | add_story | merge_stories | fix_dependency",
        "details": "Description of what was corrected",
        "story_ids_affected": ["3", "5"]
      }
    ]
  },
  "flagged_for_review": [
    {
      "story_id": "2",
      "concern": "AC-2.3 may misinterpret spec -- spec says 'debounce' but story says 'polling'",
      "confidence": "medium"
    }
  ],
  "final_stories": [
    {
      "id": "1",
      "title": "Fix bootstrap.py restart policy",
      "type": "feature",
      "description": "...",
      "acceptance_criteria": [
        {"id": "AC-1.1", "text": "Exponential backoff from 5s base to 300s max"},
        {"id": "AC-1.2", "text": "Wire startup_grace_seconds into monitor loop"}
      ],
      "files": ["src/daemon/bootstrap.py"],
      "depends_on": [],
      "risk": "high",
      "points": 3,
      "gap_sources": ["d3"],
      "drift_metadata": {
        "max_severity": "critical",
        "classification": "drifted",
        "spec_section": "BOOTSTRAP.template.md"
      }
    }
  ],
  "skipped_done": [/* verified done items */],
  "ahead_of_spec": [/* informational items */],
  "coverage_check": {
    "total_spec_deliverables": 87,
    "covered_by_stories": <count>,
    "verified_done": <count>,
    "uncovered": <count>,
    "uncovered_ids": ["d22"]
  }
}

IMPORTANT:
- final_stories is the corrected, ready-to-present story list. Re-sequence IDs (1, 2, 3, ...)
- Do NOT create standalone test stories
- All stories MUST use type "feature"
- Be conservative with auto-corrections -- when in doubt, flag for review
- The proposed stories already have 7 stories, 75 skipped_done, 2 ahead_of_spec
- Total deliverables in manifest: 87
- Verify: stories + skipped_done + ahead_of_spec should cover all 87 deliverables
